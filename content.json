[{"title":"MySQL优化案例","date":"2019-10-02T10:03:04.000Z","path":"2019/10/02/SQL优化详细笔记/","text":"6. 优化案例 单表优化 两表优化 三表优化 (1) 单表优化12345678910111213create table book( bid int(4) primary key, name varchar(20) not null, authorid int(4) not null, publicid int(4) not null, typeid int(4) not null );insert into book values(1,&apos;tjava&apos;,1,1,2) ;insert into book values(2,&apos;tc&apos;,2,1,2) ;insert into book values(3,&apos;wx&apos;,3,2,1) ;insert into book values(4,&apos;math&apos;,4,2,3) ; commit; 场景1：查询authorid=1且 typeid为2或3的 bid sql语句： explain select bid from book where typeid in(2,3) and authorid=1 order by typeid desc ; 优化一：加索引 alter table book add index idx_bta (bid,typeid,authorid); 优化过程： 1234567索引一旦进行 升级优化，需要将之前废弃的索引删掉，防止干扰。之前索引：（a,b,c) 当前索引：（a,b)会有干扰，索引删除（a,b,c)索引。 drop index idx_bta on book;根据SQL实际解析的顺序，调整索引的顺序：(虽然可以回表查询bid，但是将bid放到索引中 可以提升使用using index ;)alter table book add index idx_tab (typeid,authorid,bid); 再次优化 （之前是index级别）：思路。因为范围查询in有时会实现，因此交换 索引的顺序，将typeid in(2,3) 放到最后。 123drop index idx_tab on book; alter table book add index idx_atb (authorid,typeid,bid); explain select bid from book where authorid=1 and typeid in(2,3) order by typeid desc ; 优化结果：达到——ref级别 – 小结 1.最佳做前缀，保持索引的定义和使用的顺序一致性 2.索引需要逐步优化 3.将含In的范围查询 放到where条件的最后，防止失效 注意： 12345678910本例中同时出现了Using where（需要回原表）; Using index（不需要回原表）：原因，where authorid=1 and typeid in(2,3)中authorid在索引(authorid,typeid,bid)中，因此不需要回原表（直接在索引表中能查到）； typeid虽然也在索引(authorid,typeid,bid)中，但是含in的范围查询已经使该typeid索引失效，因此相当于没有 typeid这个索引，所以需要回原表（using where）； 例如以下没有了In，则不会出现using where explain select bid from book where authorid=1 and typeid =3 order by typeid desc ;还可以通过key_len证明In可以使索引失效。 (2) 两表优化 创建表的sql语句 1234567891011121314151617181920create table teacher2( tid int(4) primary key, cid int(4) not null);insert into teacher2 values(1,2);insert into teacher2 values(2,1);insert into teacher2 values(3,3);create table course2( cid int(4) , cname varchar(20));insert into course2 values(1,&apos;java&apos;);insert into course2 values(2,&apos;python&apos;);insert into course2 values(3,&apos;kotlin&apos;);commit; 左连接 explain select *from teacher2 t left outer join course2 c on t.cid=c.cid where c.cname=&#39;java&#39;; 优化知识补充： (1) 索引往哪张表加？ 小表驱动大表 ​ 索引建立经常使用的字段上 （本题 t.cid=c.cid可知，t.cid字段使用频繁，因此给该字段加索引） [一般情况对于左外连接，给左表加索引；右外连接，给右表加索引] 1234567891011121314151617181920212223242526小表：10大表：300 where 小表.x 10 = 大表.y 300; --循环了几次？10 大表.y 300=小表.x 10 --循环了300次 小表:10大表:300 select ...where 小表.x10=大表.x300 ; for(int i=0;i&lt;小表.length10;i++) &#123; for(int j=0;j&lt;大表.length300;j++) &#123; ... &#125; &#125; 对比： select ...where 大表.x300=小表.x10 ; for(int i=0;i&lt;大表.length300;i++) &#123; for(int j=0;j&lt;小表.length10;j++) &#123; ... &#125; &#125; 以上2个FOR循环，最终都会循环3000次；但是 对于双层循环来说：一般建议 将数据小的循环 放外层；数据大的循环放内存 (2) 优化过程 当编写 ..on t.cid=c.cid 时，将数据量小的表 放左边（假设此时t表数据量小） 12alter table teacher2 add index index_teacher2_cid(cid) ;alter table course2 add index index_course2_cname(cname); Using join buffer:extra中的一个选项，作用：Mysql引擎使用了 连接缓存。 优化后的ref级别： (3) 三表优化 三张表优化A B C 1,小表驱动大表 2,索引建立在经常查询的字段上 创建表： 12345678910111213create table test03( a1 int(4) not null, a2 int(4) not null, a3 int(4) not null, a4 int(4) not null);alter table test03 add index idx_a1_a2_a3_4(a1,a2,a3,a4) ;explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a3=3 and a4 =4 ; --推荐写法，因为 索引的使用顺序（where后面的顺序） 和 复合索引的顺序一致explain select a1,a2,a3,a4 from test03 where a4=1 and a3=2 and a2=3 and a1 =4 ; --虽然编写的顺序 和索引顺序不一致，但是 sql在真正执行前 经过了SQL优化器的调整，结果与上条SQL是一致的。--以上 2个SQL，使用了 全部的复合索引explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a4=4 order by a3; –以上SQL用到了a1 a2两个索引，该两个字段 不需要回表查询using index ;而a4因为跨列使用，造成了该索引失效，需要回表查询 因此是using where；以上可以通过 key_len进行验证 我的理解：如果跨列则会产生回表查询产生无效索引explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a3;–以上SQL出现了 using filesort(文件内排序，“多了一次额外的查找/排序”) ：不要跨列使用( where和order by 拼起来，不要跨列使用) explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a2 , a3; --不会using filesort 总结 如果 (a,b,c,d)复合索引 和使用的顺序全部一致(且不跨列使用)，则复合索引全部使用。如果部分一致(且不跨列使用)，则使用部分索引。select a,c where a = and b= and d= iwhere和order by 拼起来，不要跨列使用 using temporary:需要额外再多使用一张表. 一般出现在group by语句中；已经有表了，但不适用，必须再来一张表。 解析过程 12345from .. on.. join ..where ..group by ....having ...select dinstinct ..order by limit ...a.explain select * from test03 where a2=2 and a4=4 group by a2,a4 ;--没有using temporaryb.explain select * from test03 where a2=2 and a4=4 group by a3 ; 7.避免索引失效的一些原则 (1) 复合索引 复合索引，不要跨列或无序使用（最佳左前缀）（a,b,c） 复合索引，尽量使用全索引匹配 (a,b,c) [用到的字段都用索引] (2) 不要在索引上进行任何操作（计算、函数、类型转换），否则索引失效（单独索引不影响） 举例：book表 12345678910111213select ..where A.x = .. ; --假设A.x是索引不要：select ..where A.x*3 = .. ;假设（a,t,b）是一个复合索引explain select * from book where authorid = 1 and typeid = 2 ;--用到了at 2个索引explain select * from book where authorid = 1 and typeid*2 = 2 ;--用到了a 1个索引explain select * from book where authorid*2 = 1 and typeid*2 = 2 ;----用到了 0个索引explain select * from book where authorid*2 = 1 and typeid = 2 ;----用到了0个索引,原因：对于复合索引，如果左边失效，右侧全部失效。(a,b,c)，例如如果 b失效，则b c同时失效。drop index idx_atb on book ; alter table book add index idx_authroid (authorid) ;alter table book add index idx_typeid (typeid) ;explain select * from book where authorid*2 = 1 and typeid = 2 ; (3) 复合索引不能使用不等于（!= &lt;&gt;）或is null (is not null)，否则自身以及右侧所有全部失效。复合索引中如果有&gt;，则自身和右侧索引全部失效。 explain select * from book where authorid = 1 and typeid =2 ; 注意： SQL优化，是一种概率层面的优化。至于是否实际使用了我们的优化，需要通过explain进行推测。 12explain select * from book where authorid != 1 and typeid =2 ;explain select * from book where authorid != 1 and typeid !=2 ; 体验概率情况(&lt; &gt; =)：原因是服务层中有SQL优化器，可能会影响我们的优化。 123456789drop index idx_typeid on book;drop index idx_authroid on book;alter table book add index idx_book_at (authorid,typeid);explain select * from book where authorid = 1 and typeid =2 ;--复合索引at全部使用explain select * from book where authorid &gt; 1 and typeid =2 ; --复合索引中如果有&gt;，则自身和右侧索引全部失效。explain select * from book where authorid = 1 and typeid &gt;2 ;--复合索引at全部使用----明显的概率问题---explain select * from book where authorid &lt; 1 and typeid =2 ;--复合索引at只用到了1个索引explain select * from book where authorid &lt; 4 and typeid =2 ;--复合索引全部失效 我们学习索引优化 ，是一个大部分情况适用的结论，但由于SQL优化器等原因 该结论不是100%正确。一般而言， 范围查询（&gt; &lt; in），之后的索引失效。 (4) 补救。尽量使用索引覆盖（using index）.比如（a,b,c） select a,b,c from xx..where a= .. and b =.. ; (5) like尽量以“常量”开头，不要以’%’开头，否则索引失效 12345select * from xx where name like &apos;%x%&apos; ; --name索引失效 explain select * from teacher where tname like &apos;%x%&apos;; --tname索引失效explain select * from teacher where tname like &apos;x%&apos;;explain select tname from teacher where tname like &apos;%x%&apos;;--如果必须使用like &apos;%x%&apos;进行模糊查询，可以使用索引覆盖 挽救一部分。 （6）尽量不要使用类型转换（显示、隐式），否则索引失效 12explain select * from teacher where tname = &apos;abc&apos; ;explain select * from teacher where tname = 123 ;//程序底层将 123 -&gt; &apos;123&apos;，即进行了类型转换，因此索引失效 （7）尽量不要使用or，否则索引失效 1explain select * from teacher where tname =&apos;&apos; or tcid &gt;1 ; --将or左侧的tname 失效。 8. 其他的优化方法（1）exist和in12select ..from table where exist (子查询) ;select ..from table where 字段 in (子查询) ; 如果主查询的数据集大，则使用In , 效率高。 如果子查询的数据集大，则使用exist, 效率高。 我的理解：想要效率高：子查询数据集大就用exist,子查询数据集小就用in进行对应的子查询 语法复习： exist语法： 将主查询的结果，放到子查需结果中进行条件校验（看子查询是否有数据，如果有数据 则校验成功）, 如果 复合校验，则保留数据； 1234567&gt; select tname from teacher where exists (select * from teacher) ; &gt; --等价于select tname from teacher&gt; select tname from teacher where exists (select * from teacher where tid =9999) ;&gt;&gt; in:&gt; select ..from table where tid in (1,3,5) ;&gt; （2）order by 优化​ using filesort 有两种算法：双路排序、单路排序 （根据IO的次数） MySQL4.1之前 默认使用 双路排序；双路：扫描2次磁盘 1,从磁盘读取排序字段 ,对排序字段进行排序（在buffer中进行的排序） 2，扫描其他字段 ） 注意：IO较消耗性能 MySQL4.1之后 默认使用 单路排序 ： 只读取一次（全部字段），在buffer中进行排序。 但种单路排序 会有一定的隐患 （不一定真的是“单路|1次IO”，有可能多次IO）。 原因：如果数据量特别大，则无法 将所有字段的数据 一次性读取完毕，因此 会进行“分片读取、多次读取”。 {% asset_img 双路排序和单路排序.png%} 注意： 1，单路排序 比双路排序 会占用更多的buffer。 2，单路排序在使用时，如果数据大，可以考虑调大buffer的容量大小： set max_length_for_sort_data = 1024 单位byte 3，如果max_length_for_sort_data值太低，则mysql会自动从 单路-&gt;双路 解释：(太低：需要排序的列的总大小超过了max_length_for_sort_data定义的字节数） 提高order by查询的策略： a.选择使用单路、双路 ；调整buffer的容量大小；b.避免select * …c.复合索引 不要跨列使用 ，避免using filesortd.保证全部的排序字段 排序的一致性（都是升序 或 降序） 9. SQL排查 - 慢查询日志MySQL提供的一种日志记录，用于记录MySQL种响应时间超过阀值的SQL语句 （long_query_time，默认10秒） 查询日志默认是关闭的； 建议：开发调优是 打开，而 最终部署时关闭。 （1）基本操作 检查是否开启了 慢查询日志 ： show variables like ‘%slow_query_log%’ ; 临时开启： 123set global slow_query_log = 1 ; --在内存种开启exitservice mysql restart 永久开启： 12345/etc/my.cnf 中追加配置：vi /etc/my.cnf [mysqld]slow_query_log=1slow_query_log_file=/var/lib/mysql/localhost-slow.log 慢查询阀值： show variables like &#39;%long_query_time%&#39; ; 临时设置阀值： ​ set global long_query_time = 5 ; --设置完毕后，重新登陆后起效 （不需要重启服务） 永久设置阀值： 1234/etc/my.cnf 中追加配置：vi /etc/my.cnf [mysqld]long_query_time=3 select sleep(4);select sleep(5);select sleep(3);select sleep(3); 查询超过阀值的SQL： show global status like ‘%slow_queries%’ ; （2）慢查询的定位方式 (1)慢查询的sql被记录在了日志中，因此可以通过日志 查看具体的慢SQL。 cat /var/lib/mysql/localhost-slow.log (2)通过mysqldumpslow工具查看慢SQL,可以通过一些过滤条件 快速查找出需要定位的慢SQL mysqldumpslow –help s：排序方式r:逆序l:锁定时间g:正则匹配模式 1234567891011--获取返回记录最多的3个SQL mysqldumpslow -s r -t 3 /var/lib/mysql/localhost-slow.log--获取访问次数最多的3个SQL mysqldumpslow -s c -t 3 /var/lib/mysql/localhost-slow.log--按照时间排序，前10条包含left join查询语句的SQL mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/localhost-slow.log 语法： mysqldumpslow 各种参数 慢查询日志的文件 10.分析海量数据(1).模拟海量数据 模拟海量数据 存储过程（无return）/存储函数（有return） 1234567891011121314create table dept(dno int(5) primary key default 0,dname varchar(20) not null default &apos;&apos;,loc varchar(30) default &apos;&apos;)engine=innodb default charset=utf8;create table emp(eid int(5) primary key,ename varchar(20) not null default &apos;&apos;,job varchar(20) not null default &apos;&apos;,deptno int(5) not null default 0)engine=innodb default charset=utf8; 通过存储函数 插入海量数据： 创建存储函数：(创建随机字符串，用来模拟字段) randstring(6) -&gt;aXiayx 用于模拟员工名称 0-1 *52 [0 52) delimiter[定界符] $ 创建存储过程函数的sql语法： （1）产生随机字符串 12345678910111213delimiter $ create function randstring(n int) returns varchar(255) begin declare all_str varchar(100) default &apos;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos; ; declare return_str varchar(255) default &apos;&apos; ; declare i int default 0 ; while i&lt;n do set return_str = concat(return_str, substring(all_str, FLOOR(1+rand()*52),1)); set i=i+1 ; end while ; return return_str; end $ 注意： 若提示：Display all 780 possibilities? (y or n)，则 删除语句中所有疑似tab键，再次执行，问题解决！ 如果报错：You have an error in your SQL syntax，说明SQL语句语法有错，需要修改SQL语句； 如果报错This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you might want to use the less safe log_bin_trust_function_creators variable) 是因为 存储过程/存储函数在创建时 与之前的 开启慢查询日志冲突了 解决冲突： 1,临时解决( 开启log_bin_trust_function_creators ) show variables like ‘%log_bin_trust_function_creators%’;set global log_bin_trust_function_creators = 1; 2,永久解决： /etc/my.cnf[mysqld]下设置如下字段：log_bin_trust_function_creators = 1 （2）产生随机整数 1234567create function ran_num() returns int(5)begin declare i int default 0; set i =floor( rand()*100 ) ; return i ;end $ (3) 通过存储过程插入海量数据：emp表中 ， 10000, 100000 12345678910111213create procedure insert_emp( in eid_start int(10),in data_times int(10))begin declare i int default 0; set autocommit = 0 ; repeat insert into emp values(eid_start + i, randstring(5) ,&apos;other&apos; ,ran_num()) ; set i=i+1 ; until i=data_times end repeat ; commit ;end $ (4) 通过存储过程插入海量数据：dept表中 123456789101112create procedure insert_dept(in dno_start int(10) ,in data_times int(10))begin declare i int default 0; set autocommit = 0 ; repeat insert into dept values(dno_start+i ,randstring(6),randstring(8)) ; set i=i+1 ; until i=data_times end repeat ;commit ;end$ (5) 插入数据 1234//定义分割符 改为 ；delimiter ; call insert_emp(1000,800000) ;call insert_dept(10,30) ; (2).分析海量数据 1,profiles show profiles ; –默认关闭 show variables like ‘%profiling%’; set profiling = on ; 解释说明：show profiles ：会记录所有profiling打开之后的 全部SQL查询语句所花费的时间。缺点：不够精确，只能看到 总共消费的时间，不能看到各个硬件消费的时间（cpu io ） 2,精确分析:sql诊断 show profile all for query 上一步查询的的Query_Id show profile cpu,block io for query 上一步查询的的Query_Id 3,全局查询日志​ 记录开启之后的 全部SQL语句。 （这次全局的记录操作 仅仅在调优、开发过程中打开即可，在最终的部署实施时 一定关闭）; 操作指令：show variables like ‘%general_log%’; 执行的所有SQL记录在表中 1234&gt; show variables like &apos;%general_log%&apos;; --查看全局日志是否开启&gt; set global general_log = 1 ;--开启全局日志&gt; set global log_output=&apos;table&apos; ; --设置 将全部的SQL 记录在表中&gt; 执行的所有SQL记录在文件中 1234&gt; set global log_output=&apos;file&apos; ;&gt; set global general_log = on ;&gt; set global general_log_file=&apos;/tmp/general.log&apos; ;&gt; 开启后，会记录所有SQL ： 会被记录 mysql.general_log表中。 select * from mysql.general_log ; 11. 锁机制 定义：解决因资源共享 而造成的并发问题。 示例：买最后一件衣服X A: X 买 ： X加锁 -&gt;试衣服…下单..付款..打包 -&gt;X解锁 B: X 买：发现X已被加锁，等待X解锁， X已售空 （1）分类 操作类型 a.读锁（共享锁）： 对同一个数据（衣服），多个读操作可以同时进行，互不干扰。b.写锁（互斥锁）： 如果当前写操作没有完毕（买衣服的一系列操作），则无法进行其他的读操作、写操作 操作范围 a.表锁： ​ 一次性对一张表整体加锁。如MyISAM存储引擎使用表锁，开销小、加锁快；无死锁；但锁的范围大，容易发生锁冲突、并发度低。 b.行锁 ： ​ 一次性对一条数据加锁。如InnoDB存储引擎使用行锁，开销大，加锁慢；容易出现死锁；锁的范围较小，不易发生锁冲突，并发度高（很小概率 发生高并发问题：脏读、幻读、不可重复度、丢失更新等问题）。c.页锁 （2）实例实战1. 表锁（MyISAM） 自增操作 MYSQL/SQLSERVER 支持；oracle需要借助于序列来实现自增 举例 123456789101112create table tablelock(id int primary key auto_increment , name varchar(20) )engine myisam;insert into tablelock(name) values(&apos;a1&apos;);insert into tablelock(name) values(&apos;a2&apos;);insert into tablelock(name) values(&apos;a3&apos;);insert into tablelock(name) values(&apos;a4&apos;);insert into tablelock(name) values(&apos;a5&apos;);commit; （1）增加锁语法： ​ lock table 表1 read/write ,表2 read/write ,... （2）查看加锁的表： ​ show open tables ; 注意：会话(session) :每一个访问数据的dos命令行、数据库客户端工具 都是一个会话 （3）加读锁： ​ lock table tablelock read; ​ 会话0 123456789lock table tablelock read ;select * from tablelock; --读（查），可以delete from tablelock where id =1 ; --写（增删改），不可以select * from emp ; --读，不可以delete from emp where eid = 1; --写，不可以结论1： --如果某一个会话 对A表加了read锁，则 该会话 可以对A表进行读操作、不能进行写操作； 且 该会话不能对其他表进行读、写操作。 --即如果给A表加了读锁，则当前会话只能对A表进行读操作。 其他会话对会话0加锁后的操作情况 ： 会话1（其他会话） 12select * from tablelock; --读（查），可以delete from tablelock where id =1 ; --写，会“等待”会话0将锁释放 其他会话对其他未加锁表的操作情况： 会话2（其他会话） 1234567select * from emp ; --读（查），可以delete from emp where eid = 1; --写，可以结论2： --总结： 会话0给A表加了锁；其他会话的操作： a.可以对其他表（A表以外的表）进行读、写操作。 b.对A表：读-可以；写-需要等待释放锁。 (4) 释放锁 ​ unlock tables ; ​ （5）加写锁的操作 会话0 123lock table tablelock write ;当前会话（会话0） 可以对加了写锁的表 进行任何操作（增删改查）；但是不能 操作（增删改查）其他表 会话1（其他会话） 1对会话0中加写锁的表 可以进行增删改查的前提是：等待会话0释放写锁 ​ （6）MySQL表级锁的锁模式 ​ MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（DML）前，会自动给涉及的表加写锁。所以对MyISAM表进行操作，会有以下情况： a、对MyISAM表的读操作（加读锁），不会阻塞其他进程（会话）对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。 b、对MyISAM表的写操作（加写锁），会阻塞其他进程（会话）对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。 ​ （7）分析表锁定： 查看哪些表加了锁:show open tables ; 1代表被加了锁 分析表锁定的严重程度：show status like ‘table%’ ; 1,Table_locks_immediate :即可能获取到的锁数. 2,Table_locks_waited：需要等待的表锁数《我的理解：已经加锁的个数》(如果该值越大，说明存在越大的锁竞争) 一般建议： Table_locks_immediate/Table_locks_waited &gt; 5000， 建议采用InnoDB引擎，否则MyISAM引擎 2. 行锁(innodb)123456789create table linelock(id int(5) primary key auto_increment,name varchar(20))engine=innodb ;insert into linelock(name) values(&apos;1&apos;) ;insert into linelock(name) values(&apos;2&apos;) ;insert into linelock(name) values(&apos;3&apos;) ;insert into linelock(name) values(&apos;4&apos;) ;insert into linelock(name) values(&apos;5&apos;) ; mysql默认自动commit; oracle默认不会自动commit ; 为了研究行锁，暂时将自动commit关闭; set autocommit =0 ; 以后需要通过commit 会话0：写操作 ​ insert into linelock values( &#39;a6&#39;) ; 会话1： 写操作 同样的数据 ​ update linelock set name=&#39;ax&#39; where id = 6; 对行锁情况： 1，如果会话x对某条数据a进行 DML操作（研究时：关闭了自动commit的情况下），则其他会话必须等待会话x结束事务(commit/rollback)后 才能对数据a进行操作。 2，表锁 是通过unlock tables，也可以通过事务解锁 ; 行锁 是通过事务解锁。 行锁，操作不同数据： *会话0： *写操作 insert into linelock values(8,&#39;a8&#39;) ; 会话1：写操作， 不同的数据 12update linelock set name=&apos;ax&apos; where id = 5;行锁，一次锁一行数据；因此 如果操作的是不同数据，则不干扰。 行锁的注意事项： a.如果没有索引，则行锁会转为表锁 12show index from linelock ;alter table linelock add index idx_linelock_name(name); 会话0： 写操作 update linelock set name = ‘ai’ where name = ‘3’ ; 会话1： 写操作， 不同的数据 update linelock set name = ‘aiX’ where name = ‘4’ ; 会话0： 写操作 update linelock set name = ‘ai’ where name = 3 ; 会话1： 写操作， 不同的数据 update linelock set name = ‘aiX’ where name = 4 ; 可以发现，数据被阻塞了（加锁） 原因：如果索引类 发生了类型转换，则索引失效。 因此 此次操作，会从行锁 转为表锁。 ​ b.行锁的一种特殊情况：间隙锁：值在范围内，但却不存在 此时linelock表中 没有id=7的数据 update linelock set name =&#39;x&#39; where id &gt;1 and id&lt;9 ; 即在此where范围中，没有id=7的数据，则id=7的数据成为间隙。 间隙：Mysql会自动给 间隙 加索 -&gt;间隙锁。即 本题 会自动给id=7的数据加 间隙锁（行锁）。行锁：如果有where，则实际加索的范围 就是where后面的范围（不是实际的值） ​ (1) 如何仅仅是查询数据，能否加锁？ 可以 for update 研究学习时，将自动提交关闭： 12345set autocommit =0 ;start transaction ;begin ;select * from linelock where id =2 for update ; 通过for update对query语句进行加锁。 (2)小结： 行锁： InnoDB默认采用行锁； 缺点： 比表锁性能损耗大。 优点：并发能力强，效率高。 因此建议，高并发用InnoDB，否则用MyISAM。 行锁分析： 123456show status like &apos;%innodb_row_lock%&apos; ;Innodb_row_lock_current_waits :当前正在等待锁的数量 Innodb_row_lock_time：等待总时长。从系统启到现在 一共等待的时间Innodb_row_lock_time_avg ：平均等待时长。从系统启到现在平均等待的时间Innodb_row_lock_time_max ：最大等待时长。从系统启到现在最大一次等待的时间Innodb_row_lock_waits ： 等待次数。从系统启到现在一共等待的次数 ​ 12. 主从复制 集群在数据库的一种实现 windows:mysql 主 linux:mysql从 (1) 安装windows版mysql 如果之前计算机中安装过Mysql，要重新再安装 则需要：先卸载 再安装 先卸载： ​ 1,通过电脑自带卸载工具卸载Mysql (电脑管家也可以) ​ 2,删除一个mysql缓存文件C:\\ProgramData\\MySQL ​ 3,删除注册表regedit中所有mysql相关配置 ​ 4,重启计算机 安装MYSQL： ​ 安装时，如果出现未响应： 则重新打开D:\\MySQL\\MySQL Server 5.5\\bin\\MySQLInstanceConfig.exe 图形化客户端： SQLyog, Navicat 注意 ：如果要远程连接数据库，则需要授权远程访问。 授权远程访问 :(A-&gt;B,则再B计算机的Mysql中执行以下命令) 12GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 如果仍然报错：可能是防火墙没关闭 ： 在B关闭防火墙 service iptables stop (2) 实现主从复制 1.master将改变的数 记录在本地的 二进制日志中（binary log） ；该过程 称之为：二进制日志件事2.slave将master的binary log拷贝到自己的 relay log（中继日志文件）中3.中继日志事件，将数据读取到自己的数据库之中 MYSQL主从复制 是异步的，串行化的， 有延迟 master:slave = 1:n 配置：windows(mysql: my.ini) linux(mysql: my.cnf) 1，配置前：为了无误，先将权限(远程访问)、防火墙等处理： 关闭windows/linux防火墙： windows：右键“网络” ,linux: service iptables stop Mysql允许远程连接(windowos/linux)： 12GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 2,主机（以下代码和操作 全部在主机windows中操作）： 123456789101112131415161718my.ini[mysqld]#idserver-id=1#二进制日志文件（注意是/ 不是\\）log-bin=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-bin&quot;#错误记录文件log-error=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-error&quot;#主从同步时 忽略的数据库binlog-ignore-db=mysql#(可选)指定主从同步时，同步哪些数据库binlog-do-db=test windows中的数据库 授权哪台计算机中的数据库 是自己的从数据库： GRANT REPLICATION slave,reload,super ON *.* TO &apos;root&apos;@&apos;192.168.2.%&apos; IDENTIFIED BY &apos;root&apos;; flush privileges ; 查看主数据库的状态（每次在左主从同步前，需要观察 主机状态的最新值）show master status; （mysql-bin.000001、 107） 2,从机（以下代码和操作 全部在从机linux中操作）： 12345678910111213141516my.cnf[mysqld]server-id=2log-bin=mysql-binreplicate-do-db=testlinux中的数据 授权哪台计算机中的数控 是自己的主计算机CHANGE MASTER TO MASTER_HOST = &apos;192.168.2.2&apos;, MASTER_USER = &apos;root&apos;, MASTER_PASSWORD = &apos;root&apos;, MASTER_PORT = 3306,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=107; 如果报错：This operation cannot be performed with a running slave; run STOP SLAVE first 解决：STOP SLAVE ;再次执行上条授权语句 3,开启主从同步： 12345678910111213141516171819从机linux:start slave ;检验 show slave status \\G 主要观察： Slave_IO_Running和 Slave_SQL_Running，确保二者都是yes；如果不都是yes，则看下方的 Last_IO_Error。本次 通过 Last_IO_Error发现错误的原因是 主从使用了相同的server-id， 检查:在主从中分别查看serverid: show variables like &apos;server_id&apos; ;可以发现，在Linux中的my.cnf中设置了server-id=2，但实际执行时 确实server-id=1，原因：可能是 linux版Mysql的一个bug，也可能是 windows和Linux版本不一致造成的兼容性问题。解决改bug： set global server_id =2 ; stop slave ; set global server_id =2 ; start slave ; show slave status \\G 演示： 主windows =&gt;从 windows: 将表，插入数据 观察从数据库中该表的数据 4,主要场景； 数据库+后端 spring boot（企业级框架,目前使用较多）","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/10/02/SQL优化详细笔记/","categories":[{"name":"数据库-mysql","slug":"数据库-mysql","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/数据库-mysql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/数据库优化/"},{"name":"索引","slug":"索引","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/索引/"},{"name":"锁机制","slug":"锁机制","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/锁机制/"},{"name":"profiles分析","slug":"profiles分析","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/profiles分析/"}]},{"title":"JDK1.8的新特性","date":"2019-09-21T16:00:00.000Z","path":"2019/09/22/jdk8新特性/","text":"JDK1.8的新特性1. 前言JDK1.8已经发布很久了，在很多企业中都已经在使用。并且Spring5、SpringBoot2.0都推荐使用JDK1.8以上版本。所以我们必须与时俱进，拥抱变化。 Jdk8这个版本包含语言、编译器、库、工具和JVM等方面的十多个新特性。在本文中我们将学习以下方面的新特性： [Lambda表达式](#2. Lambda表达式) [函数式接口](#3. 函数式接口) [方法引用](#4. 方法引用) [接口的默认方法和静态方法](#5. 接口的默认方法和静态方法) [Optional](#6. Optional) [Streams](#7. Streams) [并行数组](#8. 并行数组) 2. Lambda表达式函数式编程 Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。可以使代码变的更加简洁紧凑。 2.1 基本语法：1(参数列表) -&gt; &#123;代码块&#125; 需要注意： 参数类型可省略，编译器可以自己推断 如果只有一个参数，圆括号可以省略 代码块如果只是一行代码，大括号也可以省略 如果代码块是一行，且是有结果的表达式，return可以省略 注意：事实上，把Lambda表达式可以看做是匿名内部类的一种简写方式。当然，前提是这个匿名内部类对应的必须是接口，而且接口中必须只有一个函数！Lambda表达式就是直接编写函数的：参数列表、代码体、返回值等信息，用函数来代替完整的匿名内部类！ 2.2 用法示例示例1：多个参数准备一个集合： 12// 准备一个集合List&lt;Integer&gt; list = Arrays.asList(10, 5, 25, -15, 20); 假设我们要对集合排序，我们先看JDK7的写法，需要通过匿名内部类来构造一个Comparator： 12345678// Jdk1.7写法Collections.sort(list,new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1 - o2; &#125;&#125;);System.out.println(list);// [-15, 5, 10, 20, 25] 如果是jdk8，我们可以使用新增的集合API：sort(Comparator c)方法，接收一个比较器，我们用Lambda来代替Comparator 的匿名内部类： 1234// Jdk1.8写法，参数列表的数据类型可省略：list.sort((i1,i2) -&gt; &#123; return i1 - i2;&#125;);System.out.println(list);// [-15, 5, 10, 20, 25] 对比一下Comparator中的compare()方法，你会发现：这里编写的Lambda表达式，恰恰就是compare()方法的简写形式，JDK8会把它编译为匿名内部类。是不是简单多了！ 别着急，我们发现这里的代码块只有一行代码，符合前面的省略规则，我们可以简写为： 123// Jdk8写法// 因为代码块是一个有返回值的表达式，可以省略大括号以及returnlist.sort((i1,i2) -&gt; i1 - i2); 示例2：单个参数还以刚才的集合为例，现在我们想要遍历集合中的元素，并且打印。 先用jdk1.7的方式： 1234// JDK1.7遍历并打印集合for (Integer i : list) &#123; System.out.println(i);&#125; jdk1.8给集合添加了一个方法：foreach() ，接收一个对元素进行操作的函数： 12// JDK1.8遍历并打印集合，因为只有一个参数，所以我们可以省略小括号:list.forEach(i -&gt; System.out.println(i)); 实例3：把Lambda赋值给变量Lambda表达式的实质其实还是匿名内部类，所以我们其实可以把Lambda表达式赋值给某个变量。 123456// 将一个Lambda表达式赋值给某个接口：Runnable task = () -&gt; &#123; // 这里其实是Runnable接口的匿名内部类，我们在编写run方法。 System.out.println(\"hello lambda!\");&#125;;new Thread(task).start(); 不过上面的用法很少见，一般都是直接把Lambda作为参数。 示例4：隐式finalLambda表达式的实质其实还是匿名内部类，而匿名内部类在访问外部局部变量时，要求变量必须声明为final！不过我们在使用Lambda表达式时无需声明final，这并不是说违反了匿名内部类的规则，因为Lambda底层会隐式的把变量设置为final，在后续的操作中，一定不能修改该变量： 正确示范： 1234567// 定义一个局部变量int num = -1;Runnable r = () -&gt; &#123; // 在Lambda表达式中使用局部变量num，num会被隐式声明为final System.out.println(num);&#125;;new Thread(r).start();// -1 错误案例： 1234567// 定义一个局部变量int num = -1;Runnable r = () -&gt; &#123; // 在Lambda表达式中使用局部变量num，num会被隐式声明为final，不能进行任何修改操作 System.out.println(num++);&#125;;new Thread(r).start();//报错 3. 函数式接口经过前面的学习，相信大家对于Lambda表达式已经有了初步的了解。总结一下： Lambda表达式是接口的匿名内部类的简写形式 接口必须满足：内部只有一个函数 其实这样的接口，我们称为函数式接口，我们学过的Runnable、Comparator都是函数式接口的典型代表。但是在实践中，函数接口是非常脆弱的，只要有人在接口里添加多一个方法，那么这个接口就不是函数接口了，就会导致编译失败。Java 8提供了一个特殊的注解@FunctionalInterface来克服上面提到的脆弱性并且显示地表明函数接口。而且jdk8版本中，对很多已经存在的接口都添加了@FunctionalInterface注解，例如Runnable接口： 另外，Jdk8默认提供了一些函数式接口供我们使用： 3.1 Function类型接口12345@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; // 接收一个参数T，返回一个结果R R apply(T t);&#125; Function代表的是有参数，有返回值的函数。还有很多类似的Function接口： 接口名 描述 BiFunction&lt;T,U,R&gt; 接收两个T和U类型的参数，并且返回R类型结果的函数 DoubleFunction&lt;R&gt; 接收double类型参数，并且返回R类型结果的函数 IntFunction&lt;R&gt; 接收int类型参数，并且返回R类型结果的函数 LongFunction&lt;R&gt; 接收long类型参数，并且返回R类型结果的函数 ToDoubleFunction&lt;T&gt; 接收T类型参数，并且返回double类型结果 ToIntFunction&lt;T&gt; 接收T类型参数，并且返回int类型结果 ToLongFunction&lt;T&gt; 接收T类型参数，并且返回long类型结果 DoubleToIntFunction 接收double类型参数，返回int类型结果 DoubleToLongFunction 接收double类型参数，返回long类型结果 看出规律了吗？这些都是一类函数接口，在Function基础上衍生出的，要么明确了参数不确定返回结果，要么明确结果不知道参数类型，要么两者都知道。 3.2 Consumer系列12345@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; // 接收T类型参数，不返回结果 void accept(T t);&#125; Consumer系列与Function系列一样，有各种衍生接口，这里不一一列出了。不过都具备类似的特征：那就是不返回任何结果。 3.3 Predicate系列12345@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; // 接收T类型参数，返回boolean类型结果 boolean test(T t);&#125; Predicate系列参数不固定，但是返回的一定是boolean类型。 3.4 Supplier系列12345@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; // 无需参数，返回一个T类型结果 T get();&#125; Supplier系列，英文翻译就是“供应者”，顾名思义：只产出，不收取。所以不接受任何参数，返回T类型结果。 4. 方法引用方法引用使得开发者可以将已经存在的方法作为变量来传递使用。方法引用可以和Lambda表达式配合使用。 4.1 语法：总共有四类方法引用： 语法 描述 类名::静态方法名 类的静态方法的引用 类名::非静态方法名 类的非静态方法的引用 实例对象::非静态方法名 类的指定实例对象的非静态方法引用 类名::new 类的构造方法引用 4.2 示例首先我们编写一个集合工具类，提供一个方法： 123456789101112131415public class CollectionUtil&#123; /** * 利用function将list集合中的每一个元素转换后形成新的集合返回 * @param list 要转换的源集合 * @param function 转换元素的方式 * @param &lt;T&gt; 源集合的元素类型 * @param &lt;R&gt; 转换后的元素类型 * @return */ public static &lt;T,R&gt; List&lt;R&gt; convert(List&lt;T&gt; list, Function&lt;T,R&gt; function)&#123; List&lt;R&gt; result = new ArrayList&lt;&gt;(); list.forEach(t -&gt; result.add(function.apply(t))); return result; &#125;&#125; 可以看到这个方法接收两个参数： List&lt;T&gt; list：需要进行转换的集合 Function&lt;T,R&gt;：函数接口，接收T类型，返回R类型。用这个函数接口对list中的元素T进行转换，变为R类型 接下来，我们看具体案例： 4.2.1 类的静态方法引用1List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000); 我们需要把这个集合中的元素转为十六进制保存，需要调用Integer.toHexString()方法： 123public static String toHexString(int i) &#123; return toUnsignedString0(i, 4);&#125; 这个方法接收一个 i 类型，返回一个String类型，可以用来构造一个Function的函数接口： 我们先按照Lambda原始写法，传入的Lambda表达式会被编译为Function接口，接口中通过Integer.toHexString(i)对原来集合的元素进行转换： 123// 通过Lambda表达式实现List&lt;String&gt; hexList = CollectionUtil.convert(list, i -&gt; Integer.toHexString(i));System.out.println(hexList);// [3e8, 7d0, bb8] 上面的Lambda表达式代码块中，只有对Integer.toHexString()方法的引用，没有其它代码，因此我们可以直接把方法作为参数传递，由编译器帮我们处理，这就是静态方法引用： 123// 类的静态方法引用List&lt;String&gt; hexList = CollectionUtil.convert(list, Integer::toHexString;System.out.println(hexList);// [3e8, 7d0, bb8] 4.2.2 类的非静态方法引用接下来，我们把刚刚生成的String集合hexList中的元素都变成大写，需要借助于String类的toUpperCase()方法： 123public String toUpperCase() &#123; return toUpperCase(Locale.getDefault());&#125; 这次是非静态方法，不能用类名调用，需要用实例对象，因此与刚刚的实现有一些差别，我们接收集合中的每一个字符串s。但与上面不同然后s不是toUpperCase()的参数，而是调用者： 123// 通过Lambda表达式，接收String数据，调用toUpperCase()List&lt;String&gt; upperList = CollectionUtil.convert(hexList, s -&gt; s.toUpperCase());System.out.println(upperList);// [3E8, 7D0, BB8] 因为代码体只有对toUpperCase()的调用，所以可以把方法作为参数引用传递，依然可以简写： 123// 类的成员方法List&lt;String&gt; upperList = CollectionUtil.convert(hexList, String::toUpperCase);System.out.println(upperList);// [3E8, 7D0, BB8] 4.2.3 指定实例的非静态方法引用下面一个需求是这样的，我们先定义一个数字Integer num = 2000，然后用这个数字和集合中的每个数字进行比较，比较的结果放入一个新的集合。比较对象，我们可以用Integer的compareTo方法: 123public int compareTo(Integer anotherInteger) &#123; return compare(this.value, anotherInteger.value);&#125; 先用Lambda实现， 123456List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000);// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, i -&gt; num.compareTo(i));System.out.println(compareList);// [1, 0, -1] 与前面类似，这里Lambda的代码块中，依然只有对num.compareTo(i)的调用，所以可以简写。但是，需要注意的是，这次方法的调用者不是集合的元素，而是一个外部的局部变量num，因此不能使用 Integer::compareTo，因为这样是无法确定方法的调用者。要指定调用者，需要用 对象::方法名的方式： 1234// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, num::compareTo);System.out.println(compareList);// [1, 0, -1] 4.2.4 构造函数引用最后一个场景：把集合中的数字作为毫秒值，构建出Date对象并放入集合，这里我们就需要用到Date的构造函数： 1234567/** * @param date the milliseconds since January 1, 1970, 00:00:00 GMT. * @see java.lang.System#currentTimeMillis() */public Date(long date) &#123; fastTime = date;&#125; 我们可以接收集合中的每个元素，然后把元素作为Date的构造函数参数： 1234// 将数值类型集合，转为Date类型List&lt;Date&gt; dateList = CollectionUtil.convert(list, i -&gt; new Date(i));// 这里遍历元素后需要打印，因此直接把println作为方法引用传递了dateList.forEach(System.out::println); 上面的Lambda表达式实现方式，代码体只有new Date()一行代码，因此也可以采用方法引用进行简写。但问题是，构造函数没有名称，我们只能用new关键字来代替： 123// 构造方法List&lt;Date&gt; dateList = CollectionUtil.convert(list, Date::new);dateList.forEach(System.out::println); 注意两点： 上面代码中的System.out::println 其实是 指定对象System.out的非静态方法println的引用 如果构造函数有多个，可能无法区分导致传递失败 5. 接口的默认方法和静态方法Java 8使用两个新概念扩展了接口的含义：默认方法和静态方法。 5.1 默认方法默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。 默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下： 1234567891011121314151617private interface Defaulable &#123; // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() &#123; return \"Default implementation\"; &#125; &#125;private static class DefaultableImpl implements Defaulable &#123;&#125;private static class OverridableImpl implements Defaulable &#123; @Override public String notRequired() &#123; return \"Overridden implementation\"; &#125;&#125; Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。 5.2 静态方法Java 8带来的另一个有趣的特性是在接口中可以定义静态方法，我们可以直接用接口调用这些静态方法。例子代码如下： 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; 下面的代码片段整合了默认方法和静态方法的使用场景： 12345678public static void main( String[] args ) &#123; // 调用接口的静态方法，并且传递DefaultableImpl的构造函数引用来构建对象 Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); // 调用接口的静态方法，并且传递OverridableImpl的构造函数引用来构建对象 defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() );&#125; 这段代码的输出结果如下： 12Default implementationOverridden implementation 由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如stream()、parallelStream()、forEach()和removeIf()等等。 尽管默认方法有这么多好处，但在实际开发中应该谨慎使用：在复杂的继承体系中，默认方法可能引起歧义和编译错误。如果你想了解更多细节，可以参考官方文档。 6. OptionalJava应用中最常见的bug就是空值异常。 Optional仅仅是一个容器，可以存放T类型的值或者null。它提供了一些有用的接口来避免显式的null检查，可以参考Java 8官方文档了解更多细节。 接下来看一点使用Optional的例子：可能为空的值或者某个类型的值： 1234Optional&lt; String &gt; fullName = Optional.ofNullable( null );System.out.println( \"Full Name is set? \" + fullName.isPresent() ); System.out.println( \"Full Name: \" + fullName.orElseGet( () -&gt; \"[none]\" ) ); System.out.println( fullName.map( s -&gt; \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) ); 如果Optional实例持有一个非空值，则isPresent()方法返回true，否则返回false；如果Optional实例持有null，orElseGet()方法可以接受一个lambda表达式生成的默认值；map()方法可以将现有的Optional实例的值转换成新的值；orElse()方法与orElseGet()方法类似，但是在持有null的时候返回传入的默认值，而不是通过Lambda来生成。 上述代码的输出结果如下： 123Full Name is set? falseFull Name: [none]Hey Stranger! 再看下另一个简单的例子： 12345Optional&lt; String &gt; firstName = Optional.of( \"Tom\" );System.out.println( \"First Name is set? \" + firstName.isPresent() ); System.out.println( \"First Name: \" + firstName.orElseGet( () -&gt; \"[none]\" ) ); System.out.println( firstName.map( s -&gt; \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) );System.out.println(); 这个例子的输出是： 123First Name is set? trueFirst Name: TomHey Tom! 如果想了解更多的细节，请参考官方文档。 7. Streams新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。这是目前为止最大的一次对Java库的完善，以便开发者能够写出更加有效、更加简洁和紧凑的代码。 Steam API极大得简化了集合操作（后面我们会看到不止是集合），首先看下这个叫Task的类： 12345678910111213141516171819202122232425262728public class Streams &#123; private enum Status &#123; OPEN, CLOSED &#125;; private static final class Task &#123; private final Status status; private final Integer points; Task( final Status status, final Integer points ) &#123; this.status = status; this.points = points; &#125; public Integer getPoints() &#123; return points; &#125; public Status getStatus() &#123; return status; &#125; @Override public String toString() &#123; return String.format( \"[%s, %d]\", status, points ); &#125; &#125;&#125; Task类有一个points属性，另外还有两种状态：OPEN或者CLOSED。现在假设有一个task集合： 12345final Collection&lt; Task &gt; tasks = Arrays.asList( new Task( Status.OPEN, 5 ), new Task( Status.OPEN, 13 ), new Task( Status.CLOSED, 8 ) ); 首先看一个问题：在这个task集合中一共有多少个OPEN状态的？计算出它们的points属性和。在Java 8之前，要解决这个问题，则需要使用foreach循环遍历task集合；但是在Java 8中可以利用steams解决：包括一系列元素的列表，并且支持顺序和并行处理。 12345678// Calculate total points of all active tasks using sum()final long totalPointsOfOpenTasks = tasks .stream() .filter( task -&gt; task.getStatus() == Status.OPEN ) .mapToInt( Task::getPoints ) .sum();System.out.println( \"Total points: \" + totalPointsOfOpenTasks ); 运行这个方法的控制台输出是： 1Total points: 18 这里有很多知识点值得说。首先，tasks集合被转换成steam表示；其次，在steam上的filter操作会过滤掉所有CLOSED的task；第三，mapToInt操作基于tasks集合中的每个task实例的Task::getPoints方法将task流转换成Integer集合；最后，通过sum方法计算总和，得出最后的结果。 在学习下一个例子之前，还需要记住一些steams（点此更多细节）的知识点。Steam之上的操作可分为中间操作和晚期操作。 中间操作会返回一个新的steam——执行一个中间操作（例如filter）并不会执行实际的过滤操作，而是创建一个新的steam，并将原steam中符合条件的元素放入新创建的steam。 晚期操作（例如forEach或者sum），会遍历steam并得出结果或者附带结果；在执行晚期操作之后，steam处理线已经处理完毕，就不能使用了。在几乎所有情况下，晚期操作都是立刻对steam进行遍历。 steam的另一个价值是创造性地支持并行处理（parallel processing）。对于上述的tasks集合，我们可以用下面的代码计算所有task的points之和： 12345678// Calculate total points of all tasksfinal double totalPoints = tasks .stream() .parallel() .map( task -&gt; task.getPoints() ) // or map( Task::getPoints ) .reduce( 0, Integer::sum );System.out.println( \"Total points (all tasks): \" + totalPoints ); 这里我们使用parallel方法并行处理所有的task，并使用reduce方法计算最终的结果。控制台输出如下： 1Total points（all tasks）: 26.0 对于一个集合，经常需要根据某些条件对其中的元素分组。利用steam提供的API可以很快完成这类任务，代码如下： 12345// Group tasks by their statusfinal Map&lt; Status, List&lt; Task &gt; &gt; map = tasks .stream() .collect( Collectors.groupingBy( Task::getStatus ) );System.out.println( map ); 控制台的输出如下： 1&#123;CLOSED=[[CLOSED, 8]], OPEN=[[OPEN, 5], [OPEN, 13]]&#125; 最后一个关于tasks集合的例子问题是：如何计算集合中每个任务的点数在集合中所占的比重，具体处理的代码如下： 123456789101112// Calculate the weight of each tasks (as percent of total points) final Collection&lt; String &gt; result = tasks .stream() // Stream&lt; String &gt; .mapToInt( Task::getPoints ) // IntStream .asLongStream() // LongStream .mapToDouble( points -&gt; points / totalPoints ) // DoubleStream .boxed() // Stream&lt; Double &gt; .mapToLong( weigth -&gt; ( long )( weigth * 100 ) ) // LongStream .mapToObj( percentage -&gt; percentage + \"%\" ) // Stream&lt; String&gt; .collect( Collectors.toList() ); // List&lt; String &gt; System.out.println( result ); 控制台输出结果如下： 1[19%, 50%, 30%] 最后，正如之前所说，Steam API不仅可以作用于Java集合，传统的IO操作（从文件或者网络一行一行得读取数据）可以受益于steam处理，这里有一个小例子： 1234final Path path = new File( filename ).toPath();try( Stream&lt; String &gt; lines = Files.lines( path, StandardCharsets.UTF_8 ) ) &#123; lines.onClose( () -&gt; System.out.println(\"Done!\") ).forEach( System.out::println );&#125; Stream的方法onClose() 返回一个等价的有额外句柄的Stream，当Stream的close()方法被调用的时候这个句柄会被执行。Stream API、Lambda表达式还有接口默认方法和静态方法支持的方法引用，是Java 8对软件开发的现代范式的响应。 8. 并行数组Java8版本新增了很多新的方法，用于支持并行数组处理。最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序。下面的例子论证了parallexXxx系列的方法： 123456789101112131415161718192021package com.javacodegeeks.java8.parallel.arrays;import java.util.Arrays;import java.util.concurrent.ThreadLocalRandom;public class ParallelArrays &#123; public static void main( String[] args ) &#123; long[] arrayOfLong = new long [ 20000 ]; Arrays.parallelSetAll( arrayOfLong, index -&gt; ThreadLocalRandom.current().nextInt( 1000000 ) ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + \" \" ) ); System.out.println(); Arrays.parallelSort( arrayOfLong ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + \" \" ) ); System.out.println(); &#125;&#125; 上述这些代码使用parallelSetAll()方法生成20000个随机数，然后使用parallelSort()方法进行排序。这个程序会输出乱序数组和排序数组的前10个元素。上述例子的代码输出的结果是： 12Unsorted: 591217 891976 443951 424479 766825 351964 242997 642839 119108 552378 Sorted: 39 220 263 268 325 607 655 678 723 793","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/09/22/jdk8新特性/","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/Java基础/"}],"tags":[{"name":"stream","slug":"stream","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/stream/"},{"name":"lambda","slug":"lambda","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/lambda/"},{"name":"Java中级","slug":"Java中级","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/Java中级/"}]},{"title":"Markdown 简洁语法说明","date":"2019-09-21T12:03:04.000Z","path":"2019/09/21/Markdown-简洁语法说明/","text":"0.前言一直以来都是以word文档做笔记，存在很多问题，比如代码格式、高亮等。这次公司要求使用markdown，感觉眼前一亮，以前word的问题都得到了解决，而且可以生成电子书，或者直接通过gitbook放到网络中，非常棒。 但是很多的同事可能与我一样，之前对markdown并不熟悉，所以对语法、typora的快捷键都不太熟悉，因此就有了本文。 1、基本语法1.1 多级标题语法在Markdown中，如果想将一段文字定义为标题，只需要在这段文字前面加上 #，再在 # 后加一个空格即可。还可增加二、三、四、五、六级标题，总共六级。每多一级 ，增加一个 # ，标题字号相应降低一级。如图： 快捷键在typora中，1级标题对应的快捷键是：CTRL + 1 ，其它级别分别对应2~6的数字即可 1.2 列表语法说明列表格式也很常用，它可以让你的文稿变得井井有条。在 Markdown 中，你只需要在文字前面加上 - 就可以了；如果你希望是有序列表，在文字前面加上 1. 或2. 或3. 即可。 注意：无论是- 还是 1.都需要在后面跟上一个空格 快捷键typora中并没有对应快捷键，不过在菜单中有对应选项： 1.3 引用语法说明如果你需要在文稿中引用一段别处的句子，那么就要用到「引用」格式。 在引用文字前加上 &gt; 并与文字保留一个字符的空格即可。如图： 快捷键typora中的快捷键是：CTRL+SHIFT+Q 1.4 粗体和斜体语法说明Markdown 的粗体和斜体也非常简单： 用两个 * 包含一段文本就是粗体的语法； 用一个 * 包含一段文本就是斜体的语法。 如图： 快捷键typora中的快捷键： ​ 粗体：Ctrl + B ​ 斜体：Ctrl + I ​ 下划线：Ctrl + U 1.5 链接语法说明在 Markdown 中，插入链接的语法如下： 1[链接文本](链接地址) 快捷键typora中的快捷键是：Ctrl + K 1.6 图片语法说明在 Markdown 中，插入图片的语法如下： 1![图片说明文字](链接地址) 快捷键typora中的快捷键是：Ctrl + Shift + I 1.7 分割线分割线的语法只需要另起一行，连续输入三个星号 *** 即可分割两段文字内容。 1.8 表格表格输入相对复杂，推荐使用工具自带功能实现 语法说明 快捷键typora的快捷键：Ctrl + T 弹出菜单： 生成的表格： 1.9 代码高亮语法说明行内代码块： 1`代码` 段落代码块： 123​```语言类型代码​ 123456789101112131415示例： &#123;%asset_img code.png 代码高亮%&#125;#### 快捷键行内代码：```markdownCtrl + Shift + `","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/09/21/Markdown-简洁语法说明/","categories":[{"name":"工具手册-markdown","slug":"工具手册-markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/工具手册-markdown/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/markdown/"},{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"}]},{"title":"Hello World","date":"2019-09-15T12:03:04.000Z","path":"2019/09/15/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/09/15/hello-world/","categories":[{"name":"工具手册-hexo+yilia","slug":"工具手册-hexo-yilia","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/工具手册-hexo-yilia/"}],"tags":[{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/hexo/"}]},{"title":"发布后样式加载不出来的问题","date":"2017-05-26T04:12:57.000Z","path":"2017/05/26/静态样式加载不出来/","text":"使用HEXO+GITHUB PAGES搭建个人博客，在本地服务器没有任何问题，但是在外网访问页面样式加载不出来。 因为需要修改_CONFIG.YML文件中的网址和网站根目录 12345678bash: # URL&lt;br&gt; ## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and &lt;br&gt;root as &apos;/child/&apos;&lt;br&gt; url: https://banjingwei.github.io/ban.github.io&lt;br&gt; root: /ban.github.io/&lt;br&gt; permalink: :year/:month/:day/:title/&lt;br&gt; permalink_defaults:&lt;br&gt; More info: 提示内容如下： 如果您的网站存放在子目录中，例如 HTTP://YOURSITE.COM/BLOG，则请将您的 URL 设为 HTTP://YOURSITE.COM/BLOG 并把 ROOT 设为 /BLOG/。 使用GITHUB PAGES搭建博客，网址就是：1$ https://github.com/GitHubWxw/GitHubWxw.github.io 也就是GITHUB PAGES分配给我们的网址根目录：/GitHubWxw.github.io/是搭建博客仓库的名称 root: /GitHubWxw.github.io/ Deploy to remote sites1$ hexo deploy","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2017/05/26/静态样式加载不出来/","categories":[{"name":"bug收纳筐","slug":"bug收纳筐","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/bug收纳筐/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/markdown/"},{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"}]}]