[{"title":"MySQL优化案例","date":"2019-10-02T10:03:04.000Z","path":"2019/10/02/SQL优化详细笔记/","text":"6. 优化案例 单表优化 两表优化 三表优化 (1) 单表优化12345678910111213create table book( bid int(4) primary key, name varchar(20) not null, authorid int(4) not null, publicid int(4) not null, typeid int(4) not null );insert into book values(1,&apos;tjava&apos;,1,1,2) ;insert into book values(2,&apos;tc&apos;,2,1,2) ;insert into book values(3,&apos;wx&apos;,3,2,1) ;insert into book values(4,&apos;math&apos;,4,2,3) ; commit; 场景1：查询authorid=1且 typeid为2或3的 bid sql语句： explain select bid from book where typeid in(2,3) and authorid=1 order by typeid desc ; 优化一：加索引 alter table book add index idx_bta (bid,typeid,authorid); 优化过程： 1234567索引一旦进行 升级优化，需要将之前废弃的索引删掉，防止干扰。之前索引：（a,b,c) 当前索引：（a,b)会有干扰，索引删除（a,b,c)索引。 drop index idx_bta on book;根据SQL实际解析的顺序，调整索引的顺序：(虽然可以回表查询bid，但是将bid放到索引中 可以提升使用using index ;)alter table book add index idx_tab (typeid,authorid,bid); 再次优化 （之前是index级别）：思路。因为范围查询in有时会实现，因此交换 索引的顺序，将typeid in(2,3) 放到最后。 123drop index idx_tab on book; alter table book add index idx_atb (authorid,typeid,bid); explain select bid from book where authorid=1 and typeid in(2,3) order by typeid desc ; 优化结果：达到——ref级别 – 小结 1.最佳做前缀，保持索引的定义和使用的顺序一致性 2.索引需要逐步优化 3.将含In的范围查询 放到where条件的最后，防止失效 注意： 12345678910本例中同时出现了Using where（需要回原表）; Using index（不需要回原表）：原因，where authorid=1 and typeid in(2,3)中authorid在索引(authorid,typeid,bid)中，因此不需要回原表（直接在索引表中能查到）； typeid虽然也在索引(authorid,typeid,bid)中，但是含in的范围查询已经使该typeid索引失效，因此相当于没有 typeid这个索引，所以需要回原表（using where）； 例如以下没有了In，则不会出现using where explain select bid from book where authorid=1 and typeid =3 order by typeid desc ;还可以通过key_len证明In可以使索引失效。 (2) 两表优化 创建表的sql语句 1234567891011121314151617181920create table teacher2( tid int(4) primary key, cid int(4) not null);insert into teacher2 values(1,2);insert into teacher2 values(2,1);insert into teacher2 values(3,3);create table course2( cid int(4) , cname varchar(20));insert into course2 values(1,&apos;java&apos;);insert into course2 values(2,&apos;python&apos;);insert into course2 values(3,&apos;kotlin&apos;);commit; 左连接 explain select *from teacher2 t left outer join course2 c on t.cid=c.cid where c.cname=&#39;java&#39;; 优化知识补充： (1) 索引往哪张表加？ 小表驱动大表 ​ 索引建立经常使用的字段上 （本题 t.cid=c.cid可知，t.cid字段使用频繁，因此给该字段加索引） [一般情况对于左外连接，给左表加索引；右外连接，给右表加索引] 1234567891011121314151617181920212223242526小表：10大表：300 where 小表.x 10 = 大表.y 300; --循环了几次？10 大表.y 300=小表.x 10 --循环了300次 小表:10大表:300 select ...where 小表.x10=大表.x300 ; for(int i=0;i&lt;小表.length10;i++) &#123; for(int j=0;j&lt;大表.length300;j++) &#123; ... &#125; &#125; 对比： select ...where 大表.x300=小表.x10 ; for(int i=0;i&lt;大表.length300;i++) &#123; for(int j=0;j&lt;小表.length10;j++) &#123; ... &#125; &#125; 以上2个FOR循环，最终都会循环3000次；但是 对于双层循环来说：一般建议 将数据小的循环 放外层；数据大的循环放内存 (2) 优化过程 当编写 ..on t.cid=c.cid 时，将数据量小的表 放左边（假设此时t表数据量小） 12alter table teacher2 add index index_teacher2_cid(cid) ;alter table course2 add index index_course2_cname(cname); Using join buffer:extra中的一个选项，作用：Mysql引擎使用了 连接缓存。 优化后的ref级别： (3) 三表优化 三张表优化A B C 1,小表驱动大表 2,索引建立在经常查询的字段上 创建表： 12345678910111213create table test03( a1 int(4) not null, a2 int(4) not null, a3 int(4) not null, a4 int(4) not null);alter table test03 add index idx_a1_a2_a3_4(a1,a2,a3,a4) ;explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a3=3 and a4 =4 ; --推荐写法，因为 索引的使用顺序（where后面的顺序） 和 复合索引的顺序一致explain select a1,a2,a3,a4 from test03 where a4=1 and a3=2 and a2=3 and a1 =4 ; --虽然编写的顺序 和索引顺序不一致，但是 sql在真正执行前 经过了SQL优化器的调整，结果与上条SQL是一致的。--以上 2个SQL，使用了 全部的复合索引explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a4=4 order by a3; –以上SQL用到了a1 a2两个索引，该两个字段 不需要回表查询using index ;而a4因为跨列使用，造成了该索引失效，需要回表查询 因此是using where；以上可以通过 key_len进行验证 我的理解：如果跨列则会产生回表查询产生无效索引explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a3;–以上SQL出现了 using filesort(文件内排序，“多了一次额外的查找/排序”) ：不要跨列使用( where和order by 拼起来，不要跨列使用) explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a2 , a3; --不会using filesort 总结 如果 (a,b,c,d)复合索引 和使用的顺序全部一致(且不跨列使用)，则复合索引全部使用。如果部分一致(且不跨列使用)，则使用部分索引。select a,c where a = and b= and d= iwhere和order by 拼起来，不要跨列使用 using temporary:需要额外再多使用一张表. 一般出现在group by语句中；已经有表了，但不适用，必须再来一张表。 解析过程 12345from .. on.. join ..where ..group by ....having ...select dinstinct ..order by limit ...a.explain select * from test03 where a2=2 and a4=4 group by a2,a4 ;--没有using temporaryb.explain select * from test03 where a2=2 and a4=4 group by a3 ; 7.避免索引失效的一些原则 (1) 复合索引 复合索引，不要跨列或无序使用（最佳左前缀）（a,b,c） 复合索引，尽量使用全索引匹配 (a,b,c) [用到的字段都用索引] (2) 不要在索引上进行任何操作（计算、函数、类型转换），否则索引失效（单独索引不影响） 举例：book表 12345678910111213select ..where A.x = .. ; --假设A.x是索引不要：select ..where A.x*3 = .. ;假设（a,t,b）是一个复合索引explain select * from book where authorid = 1 and typeid = 2 ;--用到了at 2个索引explain select * from book where authorid = 1 and typeid*2 = 2 ;--用到了a 1个索引explain select * from book where authorid*2 = 1 and typeid*2 = 2 ;----用到了 0个索引explain select * from book where authorid*2 = 1 and typeid = 2 ;----用到了0个索引,原因：对于复合索引，如果左边失效，右侧全部失效。(a,b,c)，例如如果 b失效，则b c同时失效。drop index idx_atb on book ; alter table book add index idx_authroid (authorid) ;alter table book add index idx_typeid (typeid) ;explain select * from book where authorid*2 = 1 and typeid = 2 ; (3) 复合索引不能使用不等于（!= &lt;&gt;）或is null (is not null)，否则自身以及右侧所有全部失效。复合索引中如果有&gt;，则自身和右侧索引全部失效。 explain select * from book where authorid = 1 and typeid =2 ; 注意： SQL优化，是一种概率层面的优化。至于是否实际使用了我们的优化，需要通过explain进行推测。 12explain select * from book where authorid != 1 and typeid =2 ;explain select * from book where authorid != 1 and typeid !=2 ; 体验概率情况(&lt; &gt; =)：原因是服务层中有SQL优化器，可能会影响我们的优化。 123456789drop index idx_typeid on book;drop index idx_authroid on book;alter table book add index idx_book_at (authorid,typeid);explain select * from book where authorid = 1 and typeid =2 ;--复合索引at全部使用explain select * from book where authorid &gt; 1 and typeid =2 ; --复合索引中如果有&gt;，则自身和右侧索引全部失效。explain select * from book where authorid = 1 and typeid &gt;2 ;--复合索引at全部使用----明显的概率问题---explain select * from book where authorid &lt; 1 and typeid =2 ;--复合索引at只用到了1个索引explain select * from book where authorid &lt; 4 and typeid =2 ;--复合索引全部失效 我们学习索引优化 ，是一个大部分情况适用的结论，但由于SQL优化器等原因 该结论不是100%正确。一般而言， 范围查询（&gt; &lt; in），之后的索引失效。 (4) 补救。尽量使用索引覆盖（using index）.比如（a,b,c） select a,b,c from xx..where a= .. and b =.. ; (5) like尽量以“常量”开头，不要以’%’开头，否则索引失效 12345select * from xx where name like &apos;%x%&apos; ; --name索引失效 explain select * from teacher where tname like &apos;%x%&apos;; --tname索引失效explain select * from teacher where tname like &apos;x%&apos;;explain select tname from teacher where tname like &apos;%x%&apos;;--如果必须使用like &apos;%x%&apos;进行模糊查询，可以使用索引覆盖 挽救一部分。 （6）尽量不要使用类型转换（显示、隐式），否则索引失效 12explain select * from teacher where tname = &apos;abc&apos; ;explain select * from teacher where tname = 123 ;//程序底层将 123 -&gt; &apos;123&apos;，即进行了类型转换，因此索引失效 （7）尽量不要使用or，否则索引失效 1explain select * from teacher where tname =&apos;&apos; or tcid &gt;1 ; --将or左侧的tname 失效。 8. 其他的优化方法（1）exist和in12select ..from table where exist (子查询) ;select ..from table where 字段 in (子查询) ; 如果主查询的数据集大，则使用In , 效率高。 如果子查询的数据集大，则使用exist, 效率高。 我的理解：想要效率高：子查询数据集大就用exist,子查询数据集小就用in进行对应的子查询 语法复习： exist语法： 将主查询的结果，放到子查需结果中进行条件校验（看子查询是否有数据，如果有数据 则校验成功）, 如果 复合校验，则保留数据； 1234567&gt; select tname from teacher where exists (select * from teacher) ; &gt; --等价于select tname from teacher&gt; select tname from teacher where exists (select * from teacher where tid =9999) ;&gt;&gt; in:&gt; select ..from table where tid in (1,3,5) ;&gt; （2）order by 优化​ using filesort 有两种算法：双路排序、单路排序 （根据IO的次数） MySQL4.1之前 默认使用 双路排序；双路：扫描2次磁盘 1,从磁盘读取排序字段 ,对排序字段进行排序（在buffer中进行的排序） 2，扫描其他字段 ） 注意：IO较消耗性能 MySQL4.1之后 默认使用 单路排序 ： 只读取一次（全部字段），在buffer中进行排序。 但种单路排序 会有一定的隐患 （不一定真的是“单路|1次IO”，有可能多次IO）。 原因：如果数据量特别大，则无法 将所有字段的数据 一次性读取完毕，因此 会进行“分片读取、多次读取”。 {% asset_img 双路排序和单路排序.png%} 注意： 1，单路排序 比双路排序 会占用更多的buffer。 2，单路排序在使用时，如果数据大，可以考虑调大buffer的容量大小： set max_length_for_sort_data = 1024 单位byte 3，如果max_length_for_sort_data值太低，则mysql会自动从 单路-&gt;双路 解释：(太低：需要排序的列的总大小超过了max_length_for_sort_data定义的字节数） 提高order by查询的策略： a.选择使用单路、双路 ；调整buffer的容量大小；b.避免select * …c.复合索引 不要跨列使用 ，避免using filesortd.保证全部的排序字段 排序的一致性（都是升序 或 降序） 9. SQL排查 - 慢查询日志MySQL提供的一种日志记录，用于记录MySQL种响应时间超过阀值的SQL语句 （long_query_time，默认10秒） 查询日志默认是关闭的； 建议：开发调优是 打开，而 最终部署时关闭。 （1）基本操作 检查是否开启了 慢查询日志 ： show variables like ‘%slow_query_log%’ ; 临时开启： 123set global slow_query_log = 1 ; --在内存种开启exitservice mysql restart 永久开启： 12345/etc/my.cnf 中追加配置：vi /etc/my.cnf [mysqld]slow_query_log=1slow_query_log_file=/var/lib/mysql/localhost-slow.log 慢查询阀值： show variables like &#39;%long_query_time%&#39; ; 临时设置阀值： ​ set global long_query_time = 5 ; --设置完毕后，重新登陆后起效 （不需要重启服务） 永久设置阀值： 1234/etc/my.cnf 中追加配置：vi /etc/my.cnf [mysqld]long_query_time=3 select sleep(4);select sleep(5);select sleep(3);select sleep(3); 查询超过阀值的SQL： show global status like ‘%slow_queries%’ ; （2）慢查询的定位方式 (1)慢查询的sql被记录在了日志中，因此可以通过日志 查看具体的慢SQL。 cat /var/lib/mysql/localhost-slow.log (2)通过mysqldumpslow工具查看慢SQL,可以通过一些过滤条件 快速查找出需要定位的慢SQL mysqldumpslow –help s：排序方式r:逆序l:锁定时间g:正则匹配模式 1234567891011--获取返回记录最多的3个SQL mysqldumpslow -s r -t 3 /var/lib/mysql/localhost-slow.log--获取访问次数最多的3个SQL mysqldumpslow -s c -t 3 /var/lib/mysql/localhost-slow.log--按照时间排序，前10条包含left join查询语句的SQL mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/localhost-slow.log 语法： mysqldumpslow 各种参数 慢查询日志的文件 10.分析海量数据(1).模拟海量数据 模拟海量数据 存储过程（无return）/存储函数（有return） 1234567891011121314create table dept(dno int(5) primary key default 0,dname varchar(20) not null default &apos;&apos;,loc varchar(30) default &apos;&apos;)engine=innodb default charset=utf8;create table emp(eid int(5) primary key,ename varchar(20) not null default &apos;&apos;,job varchar(20) not null default &apos;&apos;,deptno int(5) not null default 0)engine=innodb default charset=utf8; 通过存储函数 插入海量数据： 创建存储函数：(创建随机字符串，用来模拟字段) randstring(6) -&gt;aXiayx 用于模拟员工名称 0-1 *52 [0 52) delimiter[定界符] $ 创建存储过程函数的sql语法： （1）产生随机字符串 12345678910111213delimiter $ create function randstring(n int) returns varchar(255) begin declare all_str varchar(100) default &apos;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos; ; declare return_str varchar(255) default &apos;&apos; ; declare i int default 0 ; while i&lt;n do set return_str = concat(return_str, substring(all_str, FLOOR(1+rand()*52),1)); set i=i+1 ; end while ; return return_str; end $ 注意： 若提示：Display all 780 possibilities? (y or n)，则 删除语句中所有疑似tab键，再次执行，问题解决！ 如果报错：You have an error in your SQL syntax，说明SQL语句语法有错，需要修改SQL语句； 如果报错This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you might want to use the less safe log_bin_trust_function_creators variable) 是因为 存储过程/存储函数在创建时 与之前的 开启慢查询日志冲突了 解决冲突： 1,临时解决( 开启log_bin_trust_function_creators ) show variables like ‘%log_bin_trust_function_creators%’;set global log_bin_trust_function_creators = 1; 2,永久解决： /etc/my.cnf[mysqld]下设置如下字段：log_bin_trust_function_creators = 1 （2）产生随机整数 1234567create function ran_num() returns int(5)begin declare i int default 0; set i =floor( rand()*100 ) ; return i ;end $ (3) 通过存储过程插入海量数据：emp表中 ， 10000, 100000 12345678910111213create procedure insert_emp( in eid_start int(10),in data_times int(10))begin declare i int default 0; set autocommit = 0 ; repeat insert into emp values(eid_start + i, randstring(5) ,&apos;other&apos; ,ran_num()) ; set i=i+1 ; until i=data_times end repeat ; commit ;end $ (4) 通过存储过程插入海量数据：dept表中 123456789101112create procedure insert_dept(in dno_start int(10) ,in data_times int(10))begin declare i int default 0; set autocommit = 0 ; repeat insert into dept values(dno_start+i ,randstring(6),randstring(8)) ; set i=i+1 ; until i=data_times end repeat ;commit ;end$ (5) 插入数据 1234//定义分割符 改为 ；delimiter ; call insert_emp(1000,800000) ;call insert_dept(10,30) ; (2).分析海量数据 1,profiles show profiles ; –默认关闭 show variables like ‘%profiling%’; set profiling = on ; 解释说明：show profiles ：会记录所有profiling打开之后的 全部SQL查询语句所花费的时间。缺点：不够精确，只能看到 总共消费的时间，不能看到各个硬件消费的时间（cpu io ） 2,精确分析:sql诊断 show profile all for query 上一步查询的的Query_Id show profile cpu,block io for query 上一步查询的的Query_Id 3,全局查询日志​ 记录开启之后的 全部SQL语句。 （这次全局的记录操作 仅仅在调优、开发过程中打开即可，在最终的部署实施时 一定关闭）; 操作指令：show variables like ‘%general_log%’; 执行的所有SQL记录在表中 1234&gt; show variables like &apos;%general_log%&apos;; --查看全局日志是否开启&gt; set global general_log = 1 ;--开启全局日志&gt; set global log_output=&apos;table&apos; ; --设置 将全部的SQL 记录在表中&gt; 执行的所有SQL记录在文件中 1234&gt; set global log_output=&apos;file&apos; ;&gt; set global general_log = on ;&gt; set global general_log_file=&apos;/tmp/general.log&apos; ;&gt; 开启后，会记录所有SQL ： 会被记录 mysql.general_log表中。 select * from mysql.general_log ; 11. 锁机制 定义：解决因资源共享 而造成的并发问题。 示例：买最后一件衣服X A: X 买 ： X加锁 -&gt;试衣服…下单..付款..打包 -&gt;X解锁 B: X 买：发现X已被加锁，等待X解锁， X已售空 （1）分类 操作类型 a.读锁（共享锁）： 对同一个数据（衣服），多个读操作可以同时进行，互不干扰。b.写锁（互斥锁）： 如果当前写操作没有完毕（买衣服的一系列操作），则无法进行其他的读操作、写操作 操作范围 a.表锁： ​ 一次性对一张表整体加锁。如MyISAM存储引擎使用表锁，开销小、加锁快；无死锁；但锁的范围大，容易发生锁冲突、并发度低。 b.行锁 ： ​ 一次性对一条数据加锁。如InnoDB存储引擎使用行锁，开销大，加锁慢；容易出现死锁；锁的范围较小，不易发生锁冲突，并发度高（很小概率 发生高并发问题：脏读、幻读、不可重复度、丢失更新等问题）。c.页锁 （2）实例实战1. 表锁（MyISAM） 自增操作 MYSQL/SQLSERVER 支持；oracle需要借助于序列来实现自增 举例 123456789101112create table tablelock(id int primary key auto_increment , name varchar(20) )engine myisam;insert into tablelock(name) values(&apos;a1&apos;);insert into tablelock(name) values(&apos;a2&apos;);insert into tablelock(name) values(&apos;a3&apos;);insert into tablelock(name) values(&apos;a4&apos;);insert into tablelock(name) values(&apos;a5&apos;);commit; （1）增加锁语法： ​ lock table 表1 read/write ,表2 read/write ,... （2）查看加锁的表： ​ show open tables ; 注意：会话(session) :每一个访问数据的dos命令行、数据库客户端工具 都是一个会话 （3）加读锁： ​ lock table tablelock read; ​ 会话0 123456789lock table tablelock read ;select * from tablelock; --读（查），可以delete from tablelock where id =1 ; --写（增删改），不可以select * from emp ; --读，不可以delete from emp where eid = 1; --写，不可以结论1： --如果某一个会话 对A表加了read锁，则 该会话 可以对A表进行读操作、不能进行写操作； 且 该会话不能对其他表进行读、写操作。 --即如果给A表加了读锁，则当前会话只能对A表进行读操作。 其他会话对会话0加锁后的操作情况 ： 会话1（其他会话） 12select * from tablelock; --读（查），可以delete from tablelock where id =1 ; --写，会“等待”会话0将锁释放 其他会话对其他未加锁表的操作情况： 会话2（其他会话） 1234567select * from emp ; --读（查），可以delete from emp where eid = 1; --写，可以结论2： --总结： 会话0给A表加了锁；其他会话的操作： a.可以对其他表（A表以外的表）进行读、写操作。 b.对A表：读-可以；写-需要等待释放锁。 (4) 释放锁 ​ unlock tables ; ​ （5）加写锁的操作 会话0 123lock table tablelock write ;当前会话（会话0） 可以对加了写锁的表 进行任何操作（增删改查）；但是不能 操作（增删改查）其他表 会话1（其他会话） 1对会话0中加写锁的表 可以进行增删改查的前提是：等待会话0释放写锁 ​ （6）MySQL表级锁的锁模式 ​ MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（DML）前，会自动给涉及的表加写锁。所以对MyISAM表进行操作，会有以下情况： a、对MyISAM表的读操作（加读锁），不会阻塞其他进程（会话）对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。 b、对MyISAM表的写操作（加写锁），会阻塞其他进程（会话）对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。 ​ （7）分析表锁定： 查看哪些表加了锁:show open tables ; 1代表被加了锁 分析表锁定的严重程度：show status like ‘table%’ ; 1,Table_locks_immediate :即可能获取到的锁数. 2,Table_locks_waited：需要等待的表锁数《我的理解：已经加锁的个数》(如果该值越大，说明存在越大的锁竞争) 一般建议： Table_locks_immediate/Table_locks_waited &gt; 5000， 建议采用InnoDB引擎，否则MyISAM引擎 2. 行锁(innodb)123456789create table linelock(id int(5) primary key auto_increment,name varchar(20))engine=innodb ;insert into linelock(name) values(&apos;1&apos;) ;insert into linelock(name) values(&apos;2&apos;) ;insert into linelock(name) values(&apos;3&apos;) ;insert into linelock(name) values(&apos;4&apos;) ;insert into linelock(name) values(&apos;5&apos;) ; mysql默认自动commit; oracle默认不会自动commit ; 为了研究行锁，暂时将自动commit关闭; set autocommit =0 ; 以后需要通过commit 会话0：写操作 ​ insert into linelock values( &#39;a6&#39;) ; 会话1： 写操作 同样的数据 ​ update linelock set name=&#39;ax&#39; where id = 6; 对行锁情况： 1，如果会话x对某条数据a进行 DML操作（研究时：关闭了自动commit的情况下），则其他会话必须等待会话x结束事务(commit/rollback)后 才能对数据a进行操作。 2，表锁 是通过unlock tables，也可以通过事务解锁 ; 行锁 是通过事务解锁。 行锁，操作不同数据： *会话0： *写操作 insert into linelock values(8,&#39;a8&#39;) ; 会话1：写操作， 不同的数据 12update linelock set name=&apos;ax&apos; where id = 5;行锁，一次锁一行数据；因此 如果操作的是不同数据，则不干扰。 行锁的注意事项： a.如果没有索引，则行锁会转为表锁 12show index from linelock ;alter table linelock add index idx_linelock_name(name); 会话0： 写操作 update linelock set name = ‘ai’ where name = ‘3’ ; 会话1： 写操作， 不同的数据 update linelock set name = ‘aiX’ where name = ‘4’ ; 会话0： 写操作 update linelock set name = ‘ai’ where name = 3 ; 会话1： 写操作， 不同的数据 update linelock set name = ‘aiX’ where name = 4 ; 可以发现，数据被阻塞了（加锁） 原因：如果索引类 发生了类型转换，则索引失效。 因此 此次操作，会从行锁 转为表锁。 ​ b.行锁的一种特殊情况：间隙锁：值在范围内，但却不存在 此时linelock表中 没有id=7的数据 update linelock set name =&#39;x&#39; where id &gt;1 and id&lt;9 ; 即在此where范围中，没有id=7的数据，则id=7的数据成为间隙。 间隙：Mysql会自动给 间隙 加索 -&gt;间隙锁。即 本题 会自动给id=7的数据加 间隙锁（行锁）。行锁：如果有where，则实际加索的范围 就是where后面的范围（不是实际的值） ​ (1) 如何仅仅是查询数据，能否加锁？ 可以 for update 研究学习时，将自动提交关闭： 12345set autocommit =0 ;start transaction ;begin ;select * from linelock where id =2 for update ; 通过for update对query语句进行加锁。 (2)小结： 行锁： InnoDB默认采用行锁； 缺点： 比表锁性能损耗大。 优点：并发能力强，效率高。 因此建议，高并发用InnoDB，否则用MyISAM。 行锁分析： 123456show status like &apos;%innodb_row_lock%&apos; ;Innodb_row_lock_current_waits :当前正在等待锁的数量 Innodb_row_lock_time：等待总时长。从系统启到现在 一共等待的时间Innodb_row_lock_time_avg ：平均等待时长。从系统启到现在平均等待的时间Innodb_row_lock_time_max ：最大等待时长。从系统启到现在最大一次等待的时间Innodb_row_lock_waits ： 等待次数。从系统启到现在一共等待的次数 ​ 12. 主从复制 集群在数据库的一种实现 windows:mysql 主 linux:mysql从 (1) 安装windows版mysql 如果之前计算机中安装过Mysql，要重新再安装 则需要：先卸载 再安装 先卸载： ​ 1,通过电脑自带卸载工具卸载Mysql (电脑管家也可以) ​ 2,删除一个mysql缓存文件C:\\ProgramData\\MySQL ​ 3,删除注册表regedit中所有mysql相关配置 ​ 4,重启计算机 安装MYSQL： ​ 安装时，如果出现未响应： 则重新打开D:\\MySQL\\MySQL Server 5.5\\bin\\MySQLInstanceConfig.exe 图形化客户端： SQLyog, Navicat 注意 ：如果要远程连接数据库，则需要授权远程访问。 授权远程访问 :(A-&gt;B,则再B计算机的Mysql中执行以下命令) 12GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 如果仍然报错：可能是防火墙没关闭 ： 在B关闭防火墙 service iptables stop (2) 实现主从复制 1.master将改变的数 记录在本地的 二进制日志中（binary log） ；该过程 称之为：二进制日志件事2.slave将master的binary log拷贝到自己的 relay log（中继日志文件）中3.中继日志事件，将数据读取到自己的数据库之中 MYSQL主从复制 是异步的，串行化的， 有延迟 master:slave = 1:n 配置：windows(mysql: my.ini) linux(mysql: my.cnf) 1，配置前：为了无误，先将权限(远程访问)、防火墙等处理： 关闭windows/linux防火墙： windows：右键“网络” ,linux: service iptables stop Mysql允许远程连接(windowos/linux)： 12GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 2,主机（以下代码和操作 全部在主机windows中操作）： 123456789101112131415161718my.ini[mysqld]#idserver-id=1#二进制日志文件（注意是/ 不是\\）log-bin=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-bin&quot;#错误记录文件log-error=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-error&quot;#主从同步时 忽略的数据库binlog-ignore-db=mysql#(可选)指定主从同步时，同步哪些数据库binlog-do-db=test windows中的数据库 授权哪台计算机中的数据库 是自己的从数据库： GRANT REPLICATION slave,reload,super ON *.* TO &apos;root&apos;@&apos;192.168.2.%&apos; IDENTIFIED BY &apos;root&apos;; flush privileges ; 查看主数据库的状态（每次在左主从同步前，需要观察 主机状态的最新值）show master status; （mysql-bin.000001、 107） 2,从机（以下代码和操作 全部在从机linux中操作）： 12345678910111213141516my.cnf[mysqld]server-id=2log-bin=mysql-binreplicate-do-db=testlinux中的数据 授权哪台计算机中的数控 是自己的主计算机CHANGE MASTER TO MASTER_HOST = &apos;192.168.2.2&apos;, MASTER_USER = &apos;root&apos;, MASTER_PASSWORD = &apos;root&apos;, MASTER_PORT = 3306,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=107; 如果报错：This operation cannot be performed with a running slave; run STOP SLAVE first 解决：STOP SLAVE ;再次执行上条授权语句 3,开启主从同步： 12345678910111213141516171819从机linux:start slave ;检验 show slave status \\G 主要观察： Slave_IO_Running和 Slave_SQL_Running，确保二者都是yes；如果不都是yes，则看下方的 Last_IO_Error。本次 通过 Last_IO_Error发现错误的原因是 主从使用了相同的server-id， 检查:在主从中分别查看serverid: show variables like &apos;server_id&apos; ;可以发现，在Linux中的my.cnf中设置了server-id=2，但实际执行时 确实server-id=1，原因：可能是 linux版Mysql的一个bug，也可能是 windows和Linux版本不一致造成的兼容性问题。解决改bug： set global server_id =2 ; stop slave ; set global server_id =2 ; start slave ; show slave status \\G 演示： 主windows =&gt;从 windows: 将表，插入数据 观察从数据库中该表的数据 4,主要场景； 数据库+后端 spring boot（企业级框架,目前使用较多） 视频记录 优秀笔记地址","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/10/02/SQL优化详细笔记/","categories":[{"name":"数据库-mysql","slug":"数据库-mysql","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/数据库-mysql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/数据库优化/"},{"name":"索引","slug":"索引","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/索引/"},{"name":"锁机制","slug":"锁机制","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/锁机制/"},{"name":"profiles分析","slug":"profiles分析","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/profiles分析/"}]},{"title":"Markdown 简洁语法说明","date":"2019-09-21T12:03:04.000Z","path":"2019/09/21/Markdown-简洁语法说明/","text":"0.前言一直以来都是以word文档做笔记，存在很多问题，比如代码格式、高亮等。这次公司要求使用markdown，感觉眼前一亮，以前word的问题都得到了解决，而且可以生成电子书，或者直接通过gitbook放到网络中，非常棒。 但是很多的同事可能与我一样，之前对markdown并不熟悉，所以对语法、typora的快捷键都不太熟悉，因此就有了本文。 1、基本语法1.1 多级标题语法在Markdown中，如果想将一段文字定义为标题，只需要在这段文字前面加上 #，再在 # 后加一个空格即可。还可增加二、三、四、五、六级标题，总共六级。每多一级 ，增加一个 # ，标题字号相应降低一级。如图： 快捷键在typora中，1级标题对应的快捷键是：CTRL + 1 ，其它级别分别对应2~6的数字即可 1.2 列表语法说明列表格式也很常用，它可以让你的文稿变得井井有条。在 Markdown 中，你只需要在文字前面加上 - 就可以了；如果你希望是有序列表，在文字前面加上 1. 或2. 或3. 即可。 注意：无论是- 还是 1.都需要在后面跟上一个空格 快捷键typora中并没有对应快捷键，不过在菜单中有对应选项： 1.3 引用语法说明如果你需要在文稿中引用一段别处的句子，那么就要用到「引用」格式。 在引用文字前加上 &gt; 并与文字保留一个字符的空格即可。如图： 快捷键typora中的快捷键是：CTRL+SHIFT+Q 1.4 粗体和斜体语法说明Markdown 的粗体和斜体也非常简单： 用两个 * 包含一段文本就是粗体的语法； 用一个 * 包含一段文本就是斜体的语法。 如图： 快捷键typora中的快捷键： ​ 粗体：Ctrl + B ​ 斜体：Ctrl + I ​ 下划线：Ctrl + U 1.5 链接语法说明在 Markdown 中，插入链接的语法如下： 1[链接文本](链接地址) 快捷键typora中的快捷键是：Ctrl + K 1.6 图片语法说明在 Markdown 中，插入图片的语法如下： 1![图片说明文字](链接地址) 快捷键typora中的快捷键是：Ctrl + Shift + I 1.7 分割线分割线的语法只需要另起一行，连续输入三个星号 *** 即可分割两段文字内容。 1.8 表格表格输入相对复杂，推荐使用工具自带功能实现 语法说明 快捷键typora的快捷键：Ctrl + T 弹出菜单： 生成的表格： 1.9 代码高亮语法说明行内代码块： 1`代码` 段落代码块： 123​```语言类型代码​ 123456789101112131415示例： &#123;%asset_img code.png 代码高亮%&#125;#### 快捷键行内代码：```markdownCtrl + Shift + `","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/09/21/Markdown-简洁语法说明/","categories":[{"name":"工具手册-markdown","slug":"工具手册-markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/工具手册-markdown/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/markdown/"},{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"}]},{"title":"Hello World","date":"2019-09-15T12:03:04.000Z","path":"2019/09/15/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2019/09/15/hello-world/","categories":[{"name":"工具手册-hexo+yilia","slug":"工具手册-hexo-yilia","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/工具手册-hexo-yilia/"}],"tags":[{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"},{"name":"hexo","slug":"hexo","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/hexo/"}]},{"title":"发布后样式加载不出来的问题","date":"2017-05-26T04:12:57.000Z","path":"2017/05/26/静态样式加载不出来/","text":"使用HEXO+GITHUB PAGES搭建个人博客，在本地服务器没有任何问题，但是在外网访问页面样式加载不出来。 因为需要修改_CONFIG.YML文件中的网址和网站根目录 12345678bash: # URL&lt;br&gt; ## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and &lt;br&gt;root as &apos;/child/&apos;&lt;br&gt; url: https://banjingwei.github.io/ban.github.io&lt;br&gt; root: /ban.github.io/&lt;br&gt; permalink: :year/:month/:day/:title/&lt;br&gt; permalink_defaults:&lt;br&gt; More info: 提示内容如下： 如果您的网站存放在子目录中，例如 HTTP://YOURSITE.COM/BLOG，则请将您的 URL 设为 HTTP://YOURSITE.COM/BLOG 并把 ROOT 设为 /BLOG/。 使用GITHUB PAGES搭建博客，网址就是：1$ https://github.com/GitHubWxw/GitHubWxw.github.io 也就是GITHUB PAGES分配给我们的网址根目录：/GitHubWxw.github.io/是搭建博客仓库的名称 root: /GitHubWxw.github.io/ Deploy to remote sites1$ hexo deploy","comments":true,"link":"","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/2017/05/26/静态样式加载不出来/","categories":[{"name":"bug收纳筐","slug":"bug收纳筐","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/categories/bug收纳筐/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/markdown/"},{"name":"语法","slug":"语法","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/语法/"},{"name":"入门","slug":"入门","permalink":"https://github.com/GitHubWxw/GitHubWxw.github.io/tags/入门/"}]}]